{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6445a82d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab05.5.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fb59c7",
   "metadata": {},
   "source": [
    "# Lab 5.5: GLMs\n",
    "\n",
    "#### The code and responses you need to write are represented by `...`. There is additional documentation for each part as you go along.\n",
    "\n",
    "##### Please read carefully the introduction and the instructions for each problem.\n",
    "\n",
    "\n",
    "## Collaboration Policy\n",
    "You can submit the lab in pairs (groups of two, no more than two). **If you choose to work in a pair, please make sure to add your group member on Gradescope for both Lab 05.5 written submission and the Lab 05.5 code submission.**\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about the labs, we ask that you **write your solutions individually and do not share your code with anyone other than your partner**. If you do discuss the assignments with people other than your partner please **include their names** in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37a6371",
   "metadata": {},
   "source": [
    "**Collaborators:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bad8076",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "**For full credit, this assignment should be completed and submitted before Friday, Oct 11th, 2024 at 05:00 PM PST.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe511b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from ipywidgets import interact, interactive\n",
    "import itertools\n",
    "import hashlib\n",
    "from scipy.stats import poisson, norm, gamma\n",
    "#!pip install pymc3\n",
    "import statsmodels.api as sm\n",
    "  \n",
    "sns.set(style=\"dark\")\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "from pymc import *\n",
    "import pymc as pm\n",
    "import bambi as bmb\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72700125",
   "metadata": {},
   "source": [
    "## Review: GLMs [Adapts from Lab 05]\n",
    "\n",
    "**If you completed Q3 in Lab 5, you can copy and paste your answers into the Lab 5.5 notebook (Q0) to avoid duplicating effort.**\n",
    "\n",
    "Now, we will pivot to discussing frequentist and Bayesian approaches to generalized linear models. This question will be easier after Tuesday's lecture!\n",
    "\n",
    "## Question 0: Atlantic Hurricane Season\n",
    "\n",
    "With 30 named storms, the 2020 Atlantic hurricane season was the most active on record. Climate scientists argue that the culprit is human induced global warming. There is a an evergrowing body of research linking increased average temperatures and rising sea levels to more frequent, more intense and more destructive storms. \n",
    "\n",
    "In this lab we will investigate the number of named storms recorded since 1880, and we will argue that there is a statistically significant relationship between rising Sea Surface Temperature (SST) and the frequency of named storms.\n",
    "\n",
    "For this lab we extracted the number of tropical storms from the [HURDAT Database](https://www.nhc.noaa.gov/data/hurdat/hurdat2-1851-2019-052520.txt). We also extracted data on Sea Surface Temperatures from the [National Center for Atmosferic Research](https://climatedataguide.ucar.edu/climate-data/global-surface-temperature-data-gistemp-nasa-goddard-institute-space-studies-giss). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a311f24",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2e1e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to modify: Just run the code to load the data\n",
    "data_source = \"hurricane_data.csv\"\n",
    "df = pd.read_csv(data_source)\n",
    "df = df[[\"Year\", \"Num_Storms\", \"Temp_Anomaly\"]]\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e473914",
   "metadata": {},
   "source": [
    "### Model Specifications\n",
    "\n",
    "The `Num_Storms` column contains the number of named storms recorded each year between 1880 and 2019. The `Temp_Anomaly` column contains the deviation in yearly SST from the mean of 1951-1980.\n",
    "\n",
    "In this question, to show that there is a statistically significant relationship between rising Sea Surface Temperature (SST) and the frequency of named storms, we will model the number of named storms in Year $i$ using **Poisson Regression**:\n",
    "\n",
    "$$\\lambda_i = e^{q_0 + q_1 X_i}$$ \n",
    "\n",
    "$$C_i \\sim \\text{Poisson}(\\lambda_i),$$\n",
    "\n",
    "where $X_i$ is the SST deviation in Year $i$, and $C_i$ is the number of named storms in year $i$.\n",
    "\n",
    "This isn't something that we can easily solve from scratch, so we have to use software packages. In this question, we'll explore the two approaches to GLMs that we covered in class: \n",
    "\n",
    "1. **Q0(b): Frequentist Regression** using [`statsmodels.api`](https://www.statsmodels.org/stable/glm.html) \n",
    "2. **Q0(c) Bayesian Regression** via sampling using [`PyMC`](https://www.pymc.io/welcome.html) and [`Bambi`](https://bambinos.github.io/bambi/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e22c515",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 0(a) Understanding Check\n",
    "\n",
    "The model we described above is a GLM. What is \"Linear\" about this GLM model? What's the inverse link function? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2b8a2c",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6bfebe",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## 0(b) Frequentist Regression\n",
    "\n",
    "Let's start by considering the problem from a frequentist lens. To do this, we'll use the `statsmodels.api`, which allows us to create a model in just a few lines of code.\n",
    "\n",
    "After fitting our model, we can call the `.summary()` method, and get a breakdown of our model and some details on how well it fit our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6492abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Poisson GLM model where Temp_Anomaly is a covariate (exogenous variable): No need to modify\n",
    "freq_model = sm.GLM(df[\"Num_Storms\"], exog = sm.add_constant(df[\"Temp_Anomaly\"]), \n",
    "                  family=sm.families.Poisson())\n",
    "freq_res = freq_model.fit()\n",
    "print(freq_res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b46b7c9",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 0(b)(i) Understanding the table\n",
    "\n",
    "What variable does `Temp_Anomaly`'s `coef` in the table correspond to in our model? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68c197c",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65bc13e",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 0(b)(ii) Inspecting the results of fitting `freq_model`. \n",
    "\n",
    "Does the model suggest that increased SST relate to more storms? Is the influnce of SST on number of storms statistically significant?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db41dae0",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d559b9a",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## 0(c) Bayesian Regression via PyMC\n",
    "\n",
    "Now that we've done Poisson regression the frequentist way with the `statsmodels` package, let's try implementing it the Bayesian way! In this lab we'll explore two ways of doing this:\n",
    "1. Building the model from scratch in `PyMC`\n",
    "2. Using `Bambi`, a wrapper on `PyMC` that simplifies model construction\n",
    "\n",
    "To start, let's build our model from scratch in `PyMC`. Unlike the `statsmodels` package, `PyMC` requires us to specify our model piece by piece. That means that, as with any Bayesian parameter estimation task, we have to distill our problem setup into a likelihood and prior before we can proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95df1689",
   "metadata": {},
   "source": [
    "### 0(c)(i) Unpacking $C_i \\sim \\text{Poisson}(\\lambda_i)$\n",
    "\n",
    "Recall the problem setup:\n",
    "\n",
    "Our model involves the relationship between rising Sea Surface Temperature (SST) and the frequency of named storms, where:\n",
    "\n",
    "$$\\lambda_i = e^{q_0 + q_1 X_i}$$ \n",
    "\n",
    "$$C_i \\sim \\text{Poisson}(\\lambda_i),$$\n",
    "\n",
    "where $X_i$ is the SST deviation in Year $i$, and $C_i$ is the number of named storms in year $i$.\n",
    "\n",
    "**In the cell below, Choose the option that best fills in the blank in the following statement:**\n",
    "\n",
    "$C_i \\sim \\text{Poisson}(\\lambda_i)$ represents our _____:\n",
    "\n",
    "**A.** Prior\n",
    "\n",
    "**B.** Likelihood\n",
    "\n",
    "**C.** Posterior\n",
    "\n",
    "Your answer should be a string, either `\"A\"`, `\"B\"`, or `\"C\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86061fa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q0c_i = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349c1a3a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q0c_i\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe3b18b",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 0(c)(ii) Picking our prior(s)\n",
    "\n",
    "Now, let's examine the parameter $\\lambda_i = e^{q_0 + q_1 X_i}$. As discussed in lecture, $\\lambda_i$ is comprised of a linear function of our observations ($q^TX$) and an inverse-link function ($e$). Given the setup of our problem, answer the following questions using 1 sentence each:\n",
    "1. How many prior distributions do we need to define?\n",
    "2. What parameters will we define these prior distributions for?\n",
    "3. Since we don't have any prior information about these random variables, what distribution (i.e Normal, Beta, etc.) should we pick for their priors?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9744dbd",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f66f90f",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### 0(c)(iii) Defining our PyMC Model\n",
    "Given your answers to `q2c_i` and `q2c_ii`, you're now ready to make your PyMC model! Fill out the code cell below to build your model and sample from the posterior.\n",
    "\n",
    "**Note:** To pass the test, \n",
    "1. Do not remove the variables currently present in the model and/or add your own additional variables. Just fill in any ellipsis; the variables defined here are more than enough for you to solve the question!\n",
    "2. Make sure the name parameter you pass to each `Distribution` object matches the variable name it's assigned to. Your answers should follow the following format: \n",
    "\n",
    "```\n",
    "with pm.Model() as model:\n",
    "\n",
    "    q0 = pm.Some_Distribution('q0', ...)\n",
    "    q1 = pm.Some_Distribution('q1', ...)`\n",
    "    ...\n",
    "```\n",
    "\n",
    "**Hint 1**: Remember that random variables can be added, subtracted, multiplied, etc. just like normal numbers!\n",
    "\n",
    "**Hint 2**: Not all variables defined in a model context necessarily have to be defined using `pm.Some_Distribution(...)`. In particular, we do not need `pm.Deterministic` when defining `lam`, since we're not interested in its posterior samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffc00f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    q0 = ...\n",
    "    q1 = ...\n",
    "\n",
    "    lam = ...\n",
    "    \n",
    "    Y_obs = ...\n",
    "\n",
    "    # DO NOT CHANGE THE SAMPLING ROUTINE\n",
    "    trace = pm.sample(2000, chains = 4, random_seed = 0, return_inferencedata = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76edb9b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q0c_iii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490c03c7",
   "metadata": {},
   "source": [
    "Now that we've ran PyMC, we can visualize the posterior distributions of $q_0$ and $q_1$ and find our estimates $\\hat{q}_0$ and $\\hat{q}_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24088a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(trace, round_to=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36e15d9",
   "metadata": {},
   "source": [
    "## 0(d) Bayesian Regression via Bambi\n",
    "\n",
    "Whew! `q0(c)` took *a lot* of code just to build a simple Poisson regression. In practice, building models from scratch like this is usually unnecessary unless we're looking for a custom solution. Instead, we can rely on packages like `Bambi` that *wrap* the functionality of `PyMC` with a simpler interface purely designed for GLMs.\n",
    "\n",
    "Using [`Bambi` documentation](https://bambinos.github.io/bambi/) as a guide, fill out the code cell below to fit a Bayesian Poisson Regression model on our data. \n",
    "\n",
    "**Note 1**: To pass the autograder, make sure you pass your model the `random_seed = 0` when you fit it!\n",
    "\n",
    "**Note 2**: Notice that the `Bambi` package doesn't need us to specify a prior: when we don't specify a prior for our model parameters, Bambi automatically supplies a weakly informative one based on your data by default. For this question, we are okay with this behavior: **to pass the test, do not specify a prior on your parameters!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6906885",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_model = ...\n",
    "my_model_samples = ...\n",
    "\n",
    "az.plot_posterior(my_model_samples, round_to=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe039a4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q0d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50de26ea",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 0(e) Understanding the plots\n",
    "What the are x-axis and y-axis in each of the plots in 3d)? Your answer should be in terms of the parameters of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535ec97d",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d225c9a4",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 0(f) Comparison\n",
    "\n",
    "Compare the results of `freq_model` in 0(b) with the plot in 0(d). Are the estimates of Frequentist and Bayesian Regression close to each other? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c12f61",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dadd291",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18ee1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "from otter.export import export_notebook\n",
    "from os import path\n",
    "from IPython.display import display, HTML\n",
    "export_notebook(\"lab05.5.ipynb\", filtering=True, pagebreaks=True)\n",
    "if(path.exists('lab05.5.pdf')):\n",
    "    img = mpimg.imread('chinchilla.jpg')\n",
    "    imgplot = plt.imshow(img)\n",
    "    imgplot.axes.get_xaxis().set_visible(False)\n",
    "    imgplot.axes.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "    display(HTML(\"Download your PDF <a href='lab05.5.pdf' download>here</a>.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b12ad5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663aa279",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd40274",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q0c_i": {
     "name": "q0c_i",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert q0c_i.upper() == \"B\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q0c_iii": {
     "name": "q0c_iii",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> first_q0_10 = np.array([2.31040879, 2.28676486, 2.21883405, 2.21736877, 2.22888946,\n...        2.21329085, 2.23160438, 2.24657932, 2.27997392, 2.26348672])\n>>> assert np.allclose(trace.posterior.q0[:, :].to_numpy().flatten()[:10], first_q0_10)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> first_q1_10 = np.array([0.48528855, 0.45162568, 0.58493267, 0.56287812, 0.59027936,\n...        0.54309099, 0.42550684, 0.4674696 , 0.46644434, 0.55409565])\n>>> assert np.allclose(trace.posterior.q1[:, :].to_numpy().flatten()[:10], first_q1_10)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q0d": {
     "name": "q0d",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> bambi_ta_10 = np.array([0.4844136 , 0.4844136 , 0.52475228, 0.5088275 , 0.5088275 ,\n...        0.37721286, 0.44015103, 0.50478428, 0.40513035, 0.43697324])\n>>> \n>>> assert np.allclose(my_model_samples.posterior.Temp_Anomaly.to_numpy().flatten()[:10], bambi_ta_10)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bambi_int_10 = np.array([2.20638771, 2.20638771, 2.26402576, 2.2418237 , 2.2418237 ,\n...        2.21996355, 2.26259078, 2.22356198, 2.23562492, 2.27393475])\n>>> \n>>> assert np.allclose(my_model_samples.posterior.Intercept.to_numpy().flatten()[:10], bambi_int_10)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
